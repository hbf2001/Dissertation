{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzxIUAci7JmU","executionInfo":{"status":"ok","timestamp":1766077660360,"user_tz":-240,"elapsed":3152,"user":{"displayName":"hosam","userId":"03758088676867290092"}},"outputId":"74987eed-5d59-4ab8-943e-a6ff74504fa9"},"id":"tzxIUAci7JmU","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/Dissertation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKi98DTM7TsW","executionInfo":{"status":"ok","timestamp":1766077662274,"user_tz":-240,"elapsed":124,"user":{"displayName":"hosam","userId":"03758088676867290092"}},"outputId":"4c7068ca-3a2f-4d44-d639-9541625ad4c2"},"id":"KKi98DTM7TsW","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["chest_xray  models  notebooks  README.MD  requirements.txt\n"]}]},{"cell_type":"code","execution_count":null,"id":"fe7a1374","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fe7a1374","executionInfo":{"status":"ok","timestamp":1766069912264,"user_tz":-240,"elapsed":712106,"user":{"displayName":"hosam","userId":"03758088676867290092"}},"outputId":"4f690df5-5ac9-43a5-f85e-bf73271a7cb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5232 files belonging to 2 classes.\n","Found 624 files belonging to 2 classes.\n","Train batches: 164\n","Test batches: 20\n","Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 3s/step - accuracy: 0.8528 - loss: 0.4005 - val_accuracy: 0.8942 - val_loss: 0.2593\n","Epoch 2/2\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9637 - loss: 0.1095 - val_accuracy: 0.7612 - val_loss: 0.8985\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 0.7575 - loss: 0.9974\n","\n","Prototype Test Accuracy: 0.76\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import os\n","\n","# Define paths\n","train_dir = \"/content/drive/MyDrive/Dissertation/chest_xray/train\"\n","test_dir  = \"/content/drive/MyDrive/Dissertation/chest_xray/test\"\n","\n","\n","# Load and preprocess dataset\n","img_size = (150, 150) # Resizes all images to 150x150 pixels\n","batch_size = 32 # Processes 32 images at a time\n","\n","# Load training images\n","train_ds = keras.utils.image_dataset_from_directory(\n","    train_dir,\n","    image_size=img_size,\n","    batch_size=batch_size\n",")\n","\n","# Load test images\n","test_ds = keras.utils.image_dataset_from_directory(\n","    test_dir,\n","    image_size=img_size,\n","    batch_size=batch_size\n",")\n","\n","# Normalize pixel values\n","train_ds = train_ds.map(lambda x, y: (x / 255.0, y))\n","test_ds = test_ds.map(lambda x, y: (x / 255.0, y))\n","\n","\n","\n","# Defining a small CNN model with:\n","# 2 convolutional layers, 2 pooling layers, 2 dense layers\n","model = keras.Sequential([\n","    layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    layers.MaxPooling2D(2,2),\n","    layers.Conv2D(32, (3,3), activation='relu'),\n","    layers.MaxPooling2D(2,2),\n","    layers.Flatten(),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile model\n","model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","print(\"Train batches:\", len(train_ds))\n","print(\"Test batches:\", len(test_ds))\n","\n","\n","# Train for 2 epochs\n","history = model.fit(\n","    train_ds,\n","    validation_data=test_ds,\n","    epochs=2\n",")\n","\n","#  model evaluation\n","loss, acc = model.evaluate(test_ds)\n","print(f\"\\nPrototype Test Accuracy: {acc:.2f}\")\n"]},{"cell_type":"code","source":["# To save notebook changes to drive\n","os.makedirs(\"models\", exist_ok=True)\n","\n","model.save(\"/content/drive/MyDrive/Dissertation/models/prototype_cnn.h5\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYvf6GzO5ubb","executionInfo":{"status":"ok","timestamp":1766077675273,"user_tz":-240,"elapsed":2077,"user":{"displayName":"hosam","userId":"03758088676867290092"}},"outputId":"0e189e83-08b3-4a92-d70b-60fa9babe33c"},"id":"VYvf6GzO5ubb","execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["# !ssh-keygen -t rsa -b 4096 -C \"hbf2001@hw.ac.uk\" -f /root/.ssh/id_rsa -N \"\"\n","# !cat /root/.ssh/id_rsa.pub\n","# !mkdir -p ~/.ssh\n","# !ssh-keyscan github.com >> ~/.ssh/known_hosts\n","# !ssh -T git@github.com\n","# %cd /content/drive/MyDrive/Dissertation\n","# !git remote set-url origin git@github.com:hbf2001/Dissertation.git\n","!git pull --rebase origin master\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEcSjM7NlOCv","executionInfo":{"status":"ok","timestamp":1766080918355,"user_tz":-240,"elapsed":116,"user":{"displayName":"hosam","userId":"03758088676867290092"}},"outputId":"152228cc-49cb-4a99-90e9-fc07954820da"},"id":"bEcSjM7NlOCv","execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["error: cannot pull with rebase: You have unstaged changes.\n","error: please commit or stash them.\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}